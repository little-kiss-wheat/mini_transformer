"""
é¡¹ç›®ï¼šåŸºäºè½»é‡çº§Transformerçš„æ‰‹å†™æ–‡æœ¬åºåˆ—è¯†åˆ«
æ–‡ä»¶ï¼štrain.py
ä½œè€…ï¼šæ—æ³½è¿œ
æ—¥æœŸï¼š2026.02
åŠŸèƒ½ï¼šè®­ç»ƒMini Transformeråœ¨MNISTæ•°æ®é›†ä¸Šçš„åˆ†ç±»ä»»åŠ¡ï¼Œè®°å½•å®éªŒæ•°æ®
"""
import os
import torch
import torch.nn as nn
import torch.optim as optim
import logging
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from mini_transformer import MiniTransformer, MiniTransformerConfig

# ====================== 1. æ—¥å¿—é…ç½®ï¼ˆç§‘ç ”é¡¹ç›®å¿…å¤‡ï¼Œæ›¿ä»£printï¼‰ ======================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]  # æ‰“å°åˆ°æ§åˆ¶å°
)
logger = logging.getLogger(__name__)

# ====================== 2. å…¨å±€é…ç½®ï¼ˆç»Ÿä¸€ç®¡ç†ï¼Œæ˜“è°ƒå‚ï¼‰ ======================
class TrainConfig:
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.batch_size = 32          # æ‰¹æ¬¡å¤§å°ï¼ˆè½»é‡åŒ–ï¼‰
        self.epochs = 2               # è®­ç»ƒè½®æ•°ï¼ˆå…ˆè·‘é€šï¼‰
        self.lr = 1e-3                # å­¦ä¹ ç‡
        self.data_dir = "./data"      # æ•°æ®å­˜æ”¾è·¯å¾„
        self.save_dir = "./checkpoints"  # æ¨¡å‹ä¿å­˜è·¯å¾„
        self.model_name = "mini_transformer_best.pth"  # æ¨¡å‹æ–‡ä»¶å

# ====================== 3. æ•°æ®åŠ è½½ï¼ˆå¤ç”¨CNNé€»è¾‘ï¼Œæ ‡å‡†åŒ–ï¼‰ ======================
def load_mnist_data(config: TrainConfig):
    """åŠ è½½MNISTæ•°æ®é›†ï¼Œè¿”å›è®­ç»ƒ/æµ‹è¯•åŠ è½½å™¨"""
    # æ•°æ®é¢„å¤„ç†ï¼ˆå’ŒCNNä¸€è‡´ï¼Œä¿è¯å¯¹æ¯”å…¬å¹³ï¼‰
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # MNISTå›ºå®šæ ‡å‡†åŒ–å‚æ•°
    ])
    
    # ä¸‹è½½/åŠ è½½æ•°æ®é›†
    train_dataset = datasets.MNIST(
        root=config.data_dir, train=True, download=True, transform=transform
    )
    test_dataset = datasets.MNIST(
        root=config.data_dir, train=False, download=True, transform=transform
    )
    
    # æ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False)
    
    logger.info(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆï¼è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬ï¼Œæµ‹è¯•é›†: {len(test_dataset)} æ ·æœ¬")
    return train_loader, test_loader

# ====================== 4. è®­ç»ƒ/æµ‹è¯•å‡½æ•°ï¼ˆæ¨¡å—åŒ–ï¼Œæ˜“å¤ç”¨ï¼‰ ======================
def train_one_epoch(model, train_loader, optimizer, criterion, config: TrainConfig, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0.0
    correct = 0
    total_samples = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(config.device), target.to(config.device)
        
        # å‰å‘ä¼ æ’­
        output = model(data)
        loss = criterion(output, target)
        
        # åå‘ä¼ æ’­ + ä¼˜åŒ–
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # ç»Ÿè®¡æŒ‡æ ‡
        total_loss += loss.item() * data.size(0)
        pred = output.argmax(dim=1, keepdim=True)
        correct += pred.eq(target.view_as(pred)).sum().item()
        total_samples += data.size(0)
        
        # æ¯100æ‰¹æ¬¡æ‰“å°æ—¥å¿—
        if batch_idx % 100 == 0:
            batch_acc = 100. * correct / total_samples
            logger.info(f"Epoch {epoch} [{batch_idx*config.batch_size}/{len(train_loader.dataset)}] "
                        f"Loss: {loss.item():.4f} | Acc: {batch_acc:.2f}%")
    
    # è®¡ç®—epochçº§æŒ‡æ ‡
    avg_loss = total_loss / len(train_loader.dataset)
    avg_acc = 100. * correct / len(train_loader.dataset)
    logger.info(f"Epoch {epoch} Train - Avg Loss: {avg_loss:.4f} | Avg Acc: {avg_acc:.2f}%")
    return avg_loss, avg_acc

def evaluate(model, test_loader, criterion, config: TrainConfig):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()
    total_loss = 0.0
    correct = 0
    
    with torch.no_grad():  # å…³é—­æ¢¯åº¦ï¼ŒèŠ‚çœæ˜¾å­˜
        for data, target in test_loader:
            data, target = data.to(config.device), target.to(config.device)
            output = model(data)
            total_loss += criterion(output, target).item() * data.size(0)
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    avg_loss = total_loss / len(test_loader.dataset)
    avg_acc = 100. * correct / len(test_loader.dataset)
    logger.info(f"Test - Avg Loss: {avg_loss:.4f} | Avg Acc: {avg_acc:.2f}%\n")
    return avg_loss, avg_acc

# ====================== 5. ä¸»è®­ç»ƒæµç¨‹ï¼ˆå…¥å£å‡½æ•°ï¼‰ ======================
def main():
    # 1. åˆå§‹åŒ–é…ç½®
    train_config = TrainConfig()
    model_config = MiniTransformerConfig(
        img_size=28,
        embed_dim=64,
        num_heads=2,
        num_layers=1
    )
    
    # 2. åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(train_config.save_dir, exist_ok=True)
    
    # 3. åŠ è½½æ•°æ®
    train_loader, test_loader = load_mnist_data(train_config)
    
    # 4. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±ã€ä¼˜åŒ–å™¨
    model = MiniTransformer(model_config).to(train_config.device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=train_config.lr)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯ï¼ˆç§‘ç ”è°ƒè¯•å¿…å¤‡ï¼‰
    logger.info(f"âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼è®¾å¤‡: {train_config.device}")
    logger.info(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1000:.2f}k")
    
    # 5. å¯åŠ¨è®­ç»ƒ
    best_acc = 0.0
    for epoch in range(1, train_config.epochs + 1):
        # è®­ç»ƒ
        train_one_epoch(model, train_loader, optimizer, criterion, train_config, epoch)
        # è¯„ä¼°
        test_loss, test_acc = evaluate(model, test_loader, criterion, train_config)
        
        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if test_acc > best_acc:
            best_acc = test_acc
            torch.save({
                "epoch": epoch,
                "model_state_dict": model.state_dict(),
                "optimizer_state_dict": optimizer.state_dict(),
                "best_acc": best_acc,
            }, os.path.join(train_config.save_dir, train_config.model_name))
            logger.info(f"ğŸ“Œ ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼å‡†ç¡®ç‡: {best_acc:.2f}%")
    
    # è®­ç»ƒå®Œæˆ
    logger.info(f"ğŸ‰ è®­ç»ƒç»“æŸï¼æœ€ä¼˜æµ‹è¯•å‡†ç¡®ç‡: {best_acc:.2f}%")
    return best_acc

# ====================== 6. è¿è¡Œå…¥å£ ======================
if __name__ == "__main__":
    main()  